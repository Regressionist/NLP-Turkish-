{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self,path='data/Sentiments/content.csv',train_sentencepiece=False,batch_size=64, val_size=10):\n",
    "        self.path=path\n",
    "        self.batch_size = batch_size\n",
    "        self.val_size = val_size\n",
    "        self.total_batch_size = batch_size+val_size\n",
    "        self.minibatch_index = 0\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        if(train_sentencepiece): \n",
    "            spm.SentencePieceTrainer.Train(f'--input={self.path} --model_prefix=m --vocab_size=1250')\n",
    "        self.sp.Load(\"m.model\")\n",
    "        \n",
    "    def prep_data(self):\n",
    "        subword_counter = Counter()\n",
    "        num_of_tokens = 0\n",
    "        with open(self.path,'r') as f:\n",
    "            for line in f:\n",
    "                line_subword = self.sp.EncodeAsPieces(line)\n",
    "                subword_counter.update(self.sp.EncodeAsPieces(line))\n",
    "                num_of_tokens += len(line_subword)+1\n",
    "\n",
    "        self.subwords_itos = ['_unk_','_pad_','_eos_','_bos_'] + sorted(subword_counter,key=subword_counter.get,reverse=True)\n",
    "        self.subwords_stoi = defaultdict(lambda:0,{k:i for i,k in enumerate(self.subwords_itos)})\n",
    "\n",
    "        ids = torch.LongTensor(num_of_tokens)\n",
    "        token = 0\n",
    "        with open(self.path,'r') as f:\n",
    "            for line in f:\n",
    "                line_subword = self.sp.EncodeAsPieces(line) + ['_eos_']\n",
    "                np_arr = np.array([self.subwords_stoi[s] for s in line_subword],np.int32)\n",
    "                ids[token:token+len(line_subword)] = torch.from_numpy(np_arr)\n",
    "                token += len(line_subword)\n",
    "\n",
    "        num_batches = ids.size(0) // (self.total_batch_size)\n",
    "        ids = ids[:num_batches*self.total_batch_size]\n",
    "        self.full_data = ids.view(self.total_batch_size, -1)\n",
    "        \n",
    "    def get_minibatch(self,bptt=120):\n",
    "        if (self.minibatch_index + bptt+1 > self.full_data.size(1)):\n",
    "            self.minibatch_index=0\n",
    "        self.last_mbatch_x = self.full_data[:self.batch_size,self.minibatch_index:self.minibatch_index+bptt]\n",
    "        self.last_mbatch_y = self.full_data[:self.batch_size,1+self.minibatch_index:1+self.minibatch_index+bptt]\n",
    "        self.last_mbatch_x_val = self.full_data[self.batch_size:,self.minibatch_index:self.minibatch_index+bptt]\n",
    "        self.last_mbatch_y_val = self.full_data[self.batch_size:,1+self.minibatch_index:1+self.minibatch_index+bptt]\n",
    "        self.minibatch_index+=bptt\n",
    "        return(self.last_mbatch_x,self.last_mbatch_y,self.last_mbatch_x_val,self.last_mbatch_y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=Corpus()\n",
    "corpus.prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangModel(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, dp_prob):\n",
    "        super(LangModel,self).__init__()\n",
    "    \n",
    "        self.input_size=input_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.dropout_prob=dp_prob\n",
    "    \n",
    "        self.dropout = nn.Dropout(dp_prob)\n",
    "        self.emb_layer=nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn=nn.GRU(embedding_size, hidden_size, bidirectional=True)\n",
    "        self.Linear=nn.Linear(2*hidden_size, input_size)\n",
    "    \n",
    "    def forward(self, input_sentence, init_hidden_state):\n",
    "        #input_sentence: seq_len*batch_size\n",
    "    \n",
    "        emb=self.dropout(self.emb_layer(input_sentence))\n",
    "        #emb: seq_len*batch_size*emb_size\n",
    "    \n",
    "        output, hidden=self.rnn(emb, init_hidden_state)\n",
    "        #hidden: num_layers * num_directions, batch, hidden_size\n",
    "    \n",
    "        output=self.Linear(output.view(-1,2*hidden_size))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minibatch(inputs, targets, hidden_size, mini_batch_size, model, model_optimizer, criterion, device=device):\n",
    "    model_optimizer.zero_grad()\n",
    "    hidden_state=(torch.zeros(2, mini_batch_size, hidden_size, device=device)).detach()\n",
    "    outputs = model(inputs, hidden_state)\n",
    "    #print (outputs.size(),targets.size())\n",
    "    loss = criterion(outputs, targets.reshape(-1))\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(inputs, targets, hidden_size, validation_size,criterion, device=device):\n",
    "    with torch.no_grad():\n",
    "        hidden_state=(torch.zeros(2, validation_size, hidden_size, device=device)).detach()\n",
    "        outputs = model(inputs, hidden_state)\n",
    "        val_loss = criterion(outputs, targets.reshape(-1))\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LangModel(input_size=1376, embedding_size=300, hidden_size=512, dp_prob=0.2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(device)\n",
    "model_optimizer=optim.Adam(model.parameters())\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=512\n",
    "mini_batch_size=64\n",
    "val_size=10\n",
    "tl=[]\n",
    "vl=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1.0/100 | Training Loss: 274.2057755291462 | Validation Loss: 266.572021484375\n",
      "%---Saving the model---%\n",
      "Step: 2.0/100 | Training Loss: 12.023654393851757 | Validation Loss: 12.301753997802734\n",
      "%---Saving the model---%\n",
      "Step: 3.0/100 | Training Loss: 6.445833556354046 | Validation Loss: 6.441248416900635\n",
      "%---Saving the model---%\n",
      "Step: 4.0/100 | Training Loss: 5.551934204995632 | Validation Loss: 5.563888072967529\n",
      "%---Saving the model---%\n",
      "Step: 5.0/100 | Training Loss: 5.2104016952216625 | Validation Loss: 5.036572456359863\n",
      "%---Saving the model---%\n",
      "Step: 6.0/100 | Training Loss: 4.9375943168997765 | Validation Loss: 4.884289741516113\n",
      "%---Saving the model---%\n",
      "Step: 7.0/100 | Training Loss: 4.737070959061384 | Validation Loss: 4.797152519226074\n",
      "%---Saving the model---%\n",
      "Step: 8.0/100 | Training Loss: 4.680915292352438 | Validation Loss: 4.60063362121582\n",
      "%---Saving the model---%\n",
      "Step: 9.0/100 | Training Loss: 4.544412553310394 | Validation Loss: 4.633220195770264\n",
      "Step: 10.0/100 | Training Loss: 4.455374158918858 | Validation Loss: 4.602097511291504\n",
      "Step: 11.0/100 | Training Loss: 4.376264031976461 | Validation Loss: 4.571568012237549\n",
      "%---Saving the model---%\n",
      "Step: 12.0/100 | Training Loss: 4.343686368316412 | Validation Loss: 4.416112899780273\n",
      "%---Saving the model---%\n",
      "Step: 13.0/100 | Training Loss: 4.285904087126255 | Validation Loss: 4.5524678230285645\n",
      "Step: 14.0/100 | Training Loss: 4.200812764465809 | Validation Loss: 4.431614398956299\n",
      "Step: 15.0/100 | Training Loss: 4.173578888177872 | Validation Loss: 4.369155406951904\n",
      "%---Saving the model---%\n",
      "Step: 16.0/100 | Training Loss: 4.104052502661943 | Validation Loss: 4.408670902252197\n",
      "Step: 17.0/100 | Training Loss: 4.045367646962404 | Validation Loss: 4.526952743530273\n",
      "Step: 18.0/100 | Training Loss: 4.007080540060997 | Validation Loss: 4.456813335418701\n",
      "Step: 19.0/100 | Training Loss: 3.9668851271271706 | Validation Loss: 4.369680404663086\n",
      "Step: 20.0/100 | Training Loss: 3.885882370173931 | Validation Loss: 4.463721752166748\n",
      "Step: 21.0/100 | Training Loss: 3.852623350918293 | Validation Loss: 4.384969711303711\n",
      "Step: 22.0/100 | Training Loss: 3.8120142854750156 | Validation Loss: 4.320800304412842\n",
      "%---Saving the model---%\n",
      "Step: 23.0/100 | Training Loss: 3.7432798594236374 | Validation Loss: 4.3726067543029785\n",
      "Step: 24.0/100 | Training Loss: 3.696628049015999 | Validation Loss: 4.579098701477051\n",
      "Step: 25.0/100 | Training Loss: 3.67063856869936 | Validation Loss: 4.427908420562744\n"
     ]
    }
   ],
   "source": [
    "batch_training_loss=0\n",
    "batch_validation_loss=0\n",
    "val_loss_benchmark=1000\n",
    "for i in range(2500):\n",
    "    train_input, train_target, val_input, val_target=corpus.get_minibatch()\n",
    "    train_input=Variable(train_input.cuda()).permute(1,0)\n",
    "    train_target=Variable(train_target.cuda()).permute(1,0)\n",
    "    val_input=Variable(val_input.cuda()).permute(1,0)\n",
    "    val_target=Variable(val_target.cuda()).permute(1,0)\n",
    "    train_loss=train_minibatch(train_input, train_target, hidden_size, mini_batch_size, model, model_optimizer, criterion)\n",
    "    val_loss=validate(val_input, val_target, hidden_size, val_size,criterion)\n",
    "    batch_training_loss+=train_loss\n",
    "    batch_validation_loss+=val_loss\n",
    "    if (i+1)%100==0:\n",
    "        tl.append(batch_training_loss)\n",
    "        vl.append(batch_validation_loss)\n",
    "        print ('Step: {}/{} | Training Loss: {} | Validation Loss: {}'.format((i+1)/100, 100, batch_training_loss, batch_validation_loss))\n",
    "        if (batch_validation_loss<=val_loss_benchmark):\n",
    "            print ('%---Saving the model---%')\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'model_optimizer_state_dict': model_optimizer.state_dict(),\n",
    "                },'models/LangModel_{}.pth'.format(int((i+1)/100)))\n",
    "            val_loss_benchmark=batch_validation_loss\n",
    "        batch_training_loss=0\n",
    "        batch_validation_loss=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LangModel(\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (emb_layer): Embedding(1376, 300)\n",
       "  (rnn): GRU(300, 512, bidirectional=True)\n",
       "  (Linear): Linear(in_features=1024, out_features=1376, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('models/LangModel_22.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_optimizer.load_state_dict(checkpoint['model_optimizer_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(vl[1:])),vl[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_begin = corpus.sp.EncodeAsPieces(\"Daha once bu yonet\")\n",
    "temp=torch.from_numpy(np.array([corpus.subwords_stoi[k] for k in temp_begin],np.int64))\n",
    "temp=temp.unsqueeze(1)\n",
    "temp=temp.type(torch.cuda.LongTensor)\n",
    "temp.size()\n",
    "newOutput=[0]\n",
    "while int(newOutput[0]) != 2:\n",
    "    with torch.no_grad():\n",
    "        hidden_state=torch.zeros(2, 1, hidden_size, device=device)\n",
    "        outputs = model(temp, hidden_state)\n",
    "        newOutput = F.softmax(outputs,dim=1)\n",
    "        #newOutput=newOutput.max(1)[1][-1]\n",
    "        newOutput =torch.multinomial(newOutput[-1],1)[0]\n",
    "        newOutput=newOutput.view(1)\n",
    "        temp=torch.cat((temp, newOutput.unsqueeze(1)),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in range(1000):   \n",
    "    temp_begin = corpus.sp.EncodeAsPieces(\"Daha once bu yonet\")\n",
    "    temp=torch.from_numpy(np.array([corpus.subwords_stoi[k] for k in temp_begin],np.int64))\n",
    "    temp=temp.unsqueeze(1)\n",
    "    temp=temp.type(torch.cuda.LongTensor)\n",
    "    temp.size()\n",
    "    newOutput=[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden_state=torch.zeros(2, 1, hidden_size, device=device)\n",
    "        outputs = model(temp, hidden_state)\n",
    "    a.append(corpus.subwords_itos[int(outputs.max(1)[1][-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.subwords_itos[int(outputs.max(1)[1][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁D',\n",
       " 'a',\n",
       " 'ha',\n",
       " '▁o',\n",
       " 'n',\n",
       " 'ce',\n",
       " '▁bu',\n",
       " '▁',\n",
       " 'yo',\n",
       " 'ne',\n",
       " 't',\n",
       " 'ri',\n",
       " 'k',\n",
       " 'ın',\n",
       " 'de',\n",
       " '▁pişman',\n",
       " 'ım',\n",
       " '▁',\n",
       " 'çe',\n",
       " 'y',\n",
       " 'ebil',\n",
       " 'ebil',\n",
       " 'eceğim',\n",
       " '▁kat',\n",
       " 'ıl',\n",
       " 'madan',\n",
       " 'dım',\n",
       " '.',\n",
       " '▁tamamen',\n",
       " '▁sürü',\n",
       " ';',\n",
       " 'j',\n",
       " 'lı',\n",
       " 'm',\n",
       " '.',\n",
       " 'ama',\n",
       " '▁si',\n",
       " 'k',\n",
       " '▁De',\n",
       " '▁De',\n",
       " 'n',\n",
       " '▁yapıl',\n",
       " 'sın',\n",
       " 'ı',\n",
       " '▁di',\n",
       " 'ken',\n",
       " '▁yemeği',\n",
       " '▁olarak',\n",
       " '▁yarat',\n",
       " '_eos_']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[corpus.subwords_itos[int(k)] for k in temp.detach().cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-e904395b3242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "a=newOutput.view(1)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([551], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.zeros(1, 64, hidden_size).to(device),\n",
    "              torch.zeros(1, 64, hidden_size).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
